# A Dive into Natural Language Processing

![](https://i.imgur.com/GTH36GV.png)

‚≠ê [–≥—Ä–∞–¥–∏–µ–Ω—Ç –æ–±—Ä–µ—á–µ–Ω–Ω—ã–π](https://t.me/doomgrad) ‚Äî —Ç–µ–ª–µ–≥—Ä–∞–º –∫–∞–Ω–∞–ª –ø—Ä–æ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ.

## 1. –õ–µ–∫—Ü–∏—è. –û–±–∑–æ—Ä —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è

–†–∞—Å—Å–∫–∞–∂—É –ø—Ä–æ –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–æ–º–µ–Ω—ã –≤ DS, –≤ –∫–∞–∫–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –æ–Ω–∏ —Å–µ–π—á–∞—Å –Ω–∞—Ö–æ–¥—è—Ç—Å—è –∏ –∫–∞–∫–∏–µ –∑–∞–¥–∞—á–∏ —Å–µ–π—á–∞—Å –∞–∫—Ç—É–∞–ª—å–Ω—ã –Ω–∞ —Ä—ã–Ω–∫–µ (–≤ —Ä–∏—Ç–µ–π–ª–µ, –±–∞–Ω–∫–∞—Ö, –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ—Å—Ç–∏, –ò–ë –∏ —Ç.–¥.).

_Upd. 09.10.2021_

üé¨ https://www.youtube.com/watch?v=LT8QJcOFrwo

üó®Ô∏è https://docs.google.com/presentation/d/1YFy-Ia7qwkiQp8nlHk7__JIFeB-dAnzI

**‚ú® –û—Å–Ω–æ–≤–Ω—ã–µ –≤–∏–¥—ã –¥–∞–Ω–Ω—ã—Ö**

- –¢–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –≤—Ä–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã
- –í–∏–¥–µ–æ –∏ –∑–≤—É–∫
- –ö–∞—Ä—Ç–∏–Ω–∫–∏
- –¢–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ

**‚ú® –¢–∏–ø–∏—á–Ω—ã–µ –∑–∞–¥–∞—á–∏ ML**

- Forecasting
- Anomaly detection
- Voice recognition
- Text to Speech
- Video captioning
- Object detection
- Segmentation
- Style transfer
- Image generation
- Noise reduction
- Super Resolution
- Machine translation
- NER
- Relation extraction
- Question answering
- Classification (spam, sentiment, etc.)
- Summarization
- Topic modelling

#### Open Data Science community

- https://ods.ai

## 2. –°–µ–º–∏–Ω–∞—Ä. –î–µ–ª–∞–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫

–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –æ—Å–Ω–æ–≤–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã, –ø–æ–¥—Ö–æ–¥—ã –∏ —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é, –∫–æ—Ç–æ—Ä—ã–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤ ML/DS. –†–∞–∑–±–µ—Ä–µ–º, –∫–∞–∫ –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ. –°–¥–µ–ª–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç–∞–º. –ù–∞—á–Ω–µ–º —Ä–∞–±–æ—Ç–∞—Ç—å —Å Colab.

_Update 16.10.2021_

üé¨ https://www.youtube.com/watch?v=VJTXBDHpsus

‚ö° https://colab.research.google.com/drive/1sBavnRdQTR7NDZDgLwv6_yVnu_UY_PL2?usp=sharing

**‚ú® –ü–æ–Ω—è—Ç–∏—è –∏ —Ç–µ—Ä–º–∏–Ω—ã**

- Tokenization
- Lemmatization
- Stemming
- Distributional semantics
- Embedding
- Word2Vec
- GloVe
- fastText

## 3. –õ–µ–∫—Ü–∏—è. –í–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞. Embeddings.

–ë–∞–∑–æ–≤—ã–µ –ø–æ–¥—Ö–æ–¥—ã –∏ —Ç–µ—Ö–Ω–∏–∫–∏, —Å –∫–æ—Ç–æ—Ä—ã—Ö –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–∏–∫–ª–∞–¥–Ω—ã—Ö –∑–∞–¥–∞—á –∏ —á–∞—Å—Ç–æ –∂–µ –∏–º–∏ –∏ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è. –†–∞–∑–±–µ—Ä–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ –ø–æ–¥—Ö–æ–¥—ã –ø–æ –ø–µ—Ä–µ–≤–æ–¥—É —Ç–µ–∫—Å—Ç–æ–≤ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ. Word2Vec.

_Update 24.10.2021_

üé¨ https://www.youtube.com/watch?v=OV_QM_BuAhU

üó®Ô∏è https://docs.google.com/presentation/d/162aedK5-nubUV-Z59zQ5zMW5nnLyB8Gu

**‚ú® –ü–æ–Ω—è—Ç–∏—è –∏ —Ç–µ—Ä–º–∏–Ω—ã**

- One-hot encoding
- Bag of Words
- N-grams
- TF-IDF
- Distributional semantics
- Pointwise mutual information
- Matrix factorization
- SVD
- Word2Vec
- Subsampling
- Negative sampling

## 4. –°–µ–º–∏–Ω–∞—Ä. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤. Transfer learning

_Upd. 30.10.2021_

–ü—Ä–∏–º–µ–Ω–∏–º –±–∞–∑–æ–≤—ã–µ –ø–æ–¥—Ö–æ–¥—ã –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á. –£–∑–Ω–∞–µ–º, —á—Ç–æ —Ç–∞–∫–æ–µ transfer learning –∏ –∫–∞–∫ –Ω–∞—á–∞—Ç—å –ø—Ä–æ—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ _huggingface_.

üé¨ https://www.youtube.com/watch?v=uRAsurPHycw

‚ö° https://colab.research.google.com/drive/1xtkx4pj3v7lNKXJvD63nu4YGn7YFlAlC?usp=sharing

**‚ú® –ü–æ–Ω—è—Ç–∏—è –∏ —Ç–µ—Ä–º–∏–Ω—ã**

- Neural nets
- Text classification
- Metrics
- Transfer learning
- Pretrainig
- Huggingface
- Interview questions

**‚≠êÔ∏è –ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏**

- [–¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –∞–Ω–∞–ª–∏–∑—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—â–µ–≥–æ —Ä–∞–∑–≤–∏—Ç–∏—è –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∫ –∏–Ω—Ç–µ—Ä–≤—å—é](https://github.com/alexeygrigorev/data-science-interviews/blob/master/theory.md)
- [–í–∏–¥–µ–æ –æ—Ç Deep Learning School (–ú–§–¢–ò) –ø—Ä–æ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–µ—Ç–∏ –∏ –º–µ—Ö–∞–Ω–∏–∑–º –æ–±—É—á–µ–Ω–∏—è](https://www.youtube.com/watch?v=O0nGKKFyYT4)
- [–ó–∞–º–µ—Ç–∫–∞ –æ—Ç –ï–≤–≥–µ–Ω–∏—è –°–æ–∫–æ–ª–æ–≤–∞ –ø—Ä–æ –º–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏](https://github.com/esokolov/ml-course-msu/blob/master/ML15/lecture-notes/Sem05_metrics.pdf)

## 5. –õ–µ–∫—Ü–∏—è. –ü–µ—Ä–µ–ª–æ–º–Ω—ã–π –º–æ–º–µ–Ω—Ç –≤ ML

_Upd. 10.11.2021_

–ö–∞–∫ –ø–æ–≤–ª–∏—è–ª –º–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è –Ω–∞ —Ä–∞–∑–≤–∏—Ç–∏–µ ML. –†–∞—Å—Å–∫–∞–∂—É –ø—Ä–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ —Å–µ–π—á–∞—Å —è–≤–ª—è—é—Ç—Å—è SOTA –≤–æ –º–Ω–æ–≥–∏—Ö –æ–±–ª–∞—Å—Ç—è—Ö.

üé¨ https://www.youtube.com/watch?v=6b0MXyHbILs

üó®Ô∏è https://docs.google.com/presentation/d/1rgKZaypYtjunoptDZkvoc4JDXCcNgtlU

**‚ú® –ü–æ–Ω—è—Ç–∏—è –∏ —Ç–µ—Ä–º–∏–Ω—ã**

- –ú–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è (Attention, Self-attention)
- RNN
- LSTM
- Encoder
- Decoder
- Transformer

## 6. –°–µ–º–∏–Ω–∞—Ä. –ó–Ω–∞–∫–æ–º–∏–º—Å—è —Å PyTorch –∏ PyTorch Lightning. –ü–∏—à–µ–º –ø–µ—Ä–≤—É—é –Ω–µ–π—Ä–æ—Å–µ—Ç—å.

–ü–æ–≥–æ–≤–æ—Ä–∏–º, —á—Ç–æ —Ç–∞–∫–æ–µ PyTorch –∏ –¥–ª—è —á–µ–≥–æ –æ–Ω –Ω—É–∂–µ–Ω. –ü–æ—Ç—Ä–µ–Ω–∏—Ä—É–µ–º —Å–µ—Ç—å –Ω–∞ MNIST'–µ. –û—Ç—Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–º –≤ PyTorch Lightning, —á—Ç–æ–±—ã –±—ã–ª–æ –ø—Ä–æ—â–µ —Ä–∞–±–æ—Ç–∞—Ç—å —Å –º–æ–¥–µ–ª—å—é.

üé¨ https://www.youtube.com/watch?v=Oc-DX3xwyFA

‚ö° https://colab.research.google.com/drive/1K1hz93ceM926vyEs0Ouxbizu458GDHd0

**‚ú® –ü–æ–Ω—è—Ç–∏—è –∏ —Ç–µ—Ä–º–∏–Ω—ã**

- PyTorch
- Tensor
- Optimizer
- Loss function
- PyTorch Lightning
- DataModule
- TensorBoard

## 7. –õ–µ–∫—Ü–∏—è. –ú–∞—à–∏–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥

_Update 20.11.2021_

–ú–∞—à–∏–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ ‚Äî –¥–≤–∏–∂—É—â–∞—è —Å–∏–ª–∞ NLP. –ü–æ–≥–æ–≤–æ—Ä–∏–º –ø—Ä–æ –µ–≥–æ —Ä–∞–∑–≤–∏—Ç–∏–µ, –ø—Ä–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏, –ø—Ä–æ –ø—Ä–æ–±–ª–µ–º—ã, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –∏—Ö –æ–±—É—á–µ–Ω–∏–µ–º.

üé¨ https://youtu.be/8JqWdACYKns

üó®Ô∏è https://docs.google.com/presentation/d/1QtWcCkZQ6RqgsXohPy3Pm-t3iyIwAj5l

**‚ú® –ü–æ–Ω—è—Ç–∏—è –∏ —Ç–µ—Ä–º–∏–Ω—ã**

- Machine translation
- BLEU, NIST, METEOR
- –î–∂–æ—Ä–¥–∂—Ç–∞—É–Ω—Å–∫–∏–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç
- ALPAC report
- Parallel corpora
- RBMT. Rule-based machine translation
- EBMT. Example-based machine translation
- SMT. Statistical machine translation
- NMT. Neural machine translation

**‚≠êÔ∏è –°—Å—ã–ª–∫–∏**

- [Awesome Machine Translation](https://github.com/maidis/awesome-machine-translation)
- [OpenNMT](https://opennmt.net/)
- [–õ–µ–∫—Ü–∏—è –æ—Ç –ú–§–¢–ò –ø–æ –º–∞—à–∏–Ω–Ω–æ–º—É –ø–µ—Ä–µ–≤–æ–¥—É](https://www.youtube.com/watch?v=6HibilFua-U)
- [The first-ever multilingual model to win WMT](https://ai.facebook.com/blog/the-first-ever-multilingual-model-to-win-wmt-beating-out-bilingual-models/)
- [mT5](https://github.com/google-research/multilingual-t5)
- [ruT5, ruRoBERTa, ruBERT](https://habr.com/ru/company/sberbank/blog/567776/)


## 8. –°–µ–º–∏–Ω–∞—Ä. –ú–∞—à–∏–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥

_Upd. 26.11.2021_

–°–¥–µ–ª–∞–µ–º —Ä—É—Å—Å–∫–æ-–∞–Ω–≥–ª–∏–π—Å–∫–∏–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫. –ó–∞—Ñ–∞–π–Ω—Ç—é–Ω–∏–º –º–æ–¥–µ–ª—å mT5, –∫–æ—Ç–æ—Ä—É—é –º–æ–∂–Ω–æ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥ –º–Ω–æ–∂–µ—Å—Ç–≤–æ –ø—Ä–∏–∫–ª–∞–¥–Ω—ã—Ö –∑–∞–¥–∞—á. –ü—Ä–æ —ç—Ç–æ —Ç–æ–∂–µ –ø–æ–≥–æ–≤–æ—Ä–∏–º.

üé¨ https://www.youtube.com/watch?v=vVnYib1MiYY&t=732s

‚ö° https://colab.research.google.com/drive/1KEGej1rIWBGpljZSMCjj7_MFv3c7DG3L

**‚ú® –ü–æ–Ω—è—Ç–∏—è –∏ —Ç–µ—Ä–º–∏–Ω—ã**

- –ú–∞—à–∏–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥
- T5
- mT5
- Fine-tuning
- Multitask model training

---

_tg: [@averkij](https://t.me/averkij)_ _[@doomgrad](https://t.me/doomgrad)_
